{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "A few examples to show how to use the classes from the package `catede` in order to estimate quantities such the Shannon entropy and the Kullback-Leibler divergence from data. \n",
    "\n",
    "## The `Experiment` class \n",
    "In these examples we generate $K=20^3$ categories distributed as sequeunces of length $L=3$ generated as a $20$ states Markov chain with random transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catede.handle_ngrams import markov_class\n",
    "from catede.estimate import Experiment\n",
    "\n",
    "seed_1 = 12345                                          # rng seed\n",
    "\n",
    "#  simulation  #\n",
    "A = 20                                                  # n. of states\n",
    "L = 3                                                   # length of the L-grams\n",
    "K = A ** L                                              # n. categories a priori\n",
    "\n",
    "mobj_1 = markov_class( L, n_states=A, seed=seed_1 )     # random Markov matrix\n",
    "\n",
    "size = int(5e4)                                         # sample size\n",
    "seqs_1 = mobj_1.generate_counts( size, seed=seed_1 )    # generate histogram of counts\n",
    "exact_shannon = mobj_1.exact_shannon()                  # exact Shannon entropy\n",
    "\n",
    "exp_1 = Experiment( seqs_1, categories=K )              # first experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shannon entropy estimation\n",
    "\n",
    "$$ S (q)= - \\sum_{i=1}^{K} q_{i} \\log q_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shannon entropy\n",
      "exact : 8.592\n",
      "naive : 8.509\n",
      "CAE : 8.571\n",
      "NSB : 8.589 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "naive = exp_1.shannon( method='naive' ) \n",
    "cae = exp_1.shannon( method='Chao-Shen' ) \n",
    "nsb, nsb_std = exp_1.shannon( method='NSB', error=True ) \n",
    "\n",
    "print(\"Shannon entropy\")\n",
    "print(f\"exact : {exact_shannon:.3f}\")\n",
    "print(f\"naive : {naive:.3f}\")\n",
    "print(f\"CAE : {cae:.3f}\")\n",
    "print(f\"NSB : {nsb:.3f} +- {nsb_std:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpson index estimation\n",
    "\n",
    "$$ \\lambda (q)= \\sum_{i=1}^{K} {q_{i}}^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpson index\n",
      "exact : 0.000227\n",
      "naive : 0.000247\n",
      "CAE : 0.000239\n",
      "NSB : 0.000233 +- 0.000001\n"
     ]
    }
   ],
   "source": [
    "exact_simpson = mobj_1.exact_simpson()\n",
    "naive = exp_1.simpson(method='naive')\n",
    "cae = exp_1.simpson(method='Chao-Shen') \n",
    "nsb, nsb_std = exp_1.simpson(method='NSB', error=True)\n",
    "\n",
    "print(\"Simpson index\")\n",
    "print(f\"exact : {exact_simpson:.6f}\")\n",
    "print(f\"naive : {naive:.6f}\")\n",
    "print(f\"CAE : {cae:.6f}\")\n",
    "print(f\"NSB : {nsb:.6f} +- {nsb_std:.6f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `Divergence` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catede.estimate import Divergence\n",
    "\n",
    "# simulation of an independent second system\n",
    "seed_2 = 54321                                          # rng seed\n",
    "\n",
    "mobj_2 = markov_class(L, n_states=A, seed=seed_2)       # random Markov matrix generation\n",
    "seqs_2 = mobj_2.generate_counts(size, seed=seed_2)      # generate histogram of counts\n",
    "exact_sh_entropy_2 = mobj_2.exact_shannon()             # exact Shannon entropy  \n",
    "exp_2 = Experiment(seqs_2, categories=K)                # second experiment\n",
    "div_to1from2 = Divergence(exp_1, exp_2)                 # divergence class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kullback-Leibler divergence estimation\n",
    "\n",
    "$$ D_{\\rm KL} \\left( q \\Vert t \\right) = \\sum_{i=1}^{K} q_{i} \\log \\frac{q_{i}}{t_{i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullback Leilber divergence\n",
      "exact : 0.949\n",
      "naive : 0.587\n",
      "Z : 0.828\n",
      "DPM : 0.935 +- 0.011\n"
     ]
    }
   ],
   "source": [
    "# Kullback Leibler divergence estimation #\n",
    "exact_DKL_to1from2 = mobj_1.exact_kullbackleibler(mobj_2)\n",
    "naive = div_to1from2.kullback_leibler(method='naive')\n",
    "zhang = div_to1from2.kullback_leibler(method='Zhang-Grabchak', error=True) \n",
    "dpm, dpm_std = div_to1from2.kullback_leibler(method='DPM', error=True) \n",
    "\n",
    "print(\"Kullback Leilber divergence\")\n",
    "print(f\"exact : { exact_DKL_to1from2:.3f}\")\n",
    "print(f\"naive : {naive:.3f}\")\n",
    "print(f\"Z : {zhang:.3f}\")\n",
    "print(f\"DPM : {dpm:.3f} +- {dpm_std:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squared Hellinger divergence estimation\n",
    "\n",
    "$$ D_{\\rm H}^2 \\left( q \\Vert t \\right) = 1 - \\sum_{i=1}^{K} \\sqrt{q_{i}} \\sqrt{t_{i}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared Hellinger divergence\n",
      "exact : 0.204\n",
      "naive : 0.278\n",
      "DPM : 0.202 +- 0.002\n"
     ]
    }
   ],
   "source": [
    "# Squared Hellinger divergence estimation #\n",
    "exact_DH_to1from2 = mobj_1.exact_squared_hellinger(mobj_2)\n",
    "naive = div_to1from2.squared_hellinger(method='naive')\n",
    "dpm, dpm_std = div_to1from2.squared_hellinger(method='DPM', error=True) \n",
    "\n",
    "print(\"Squared Hellinger divergence\")\n",
    "print(f\"exact : { exact_DH_to1from2:.3f}\")\n",
    "print(f\"naive : {naive:.3f}\")\n",
    "print(f\"DPM : {dpm:.3f} +- {dpm_std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ca6294cbb32705ba8e9d5f1c61ac24f2b2b51f4ed14a5137959c5b73ca963d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
